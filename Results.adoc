:encoding: utf-8
:imagesdir: img
:cpp: C++

== Results

Here we show results from the areas

- Space Mission Design
- Protein Folding
- Circle in Square Packing

See https://github.com/dietmarwo/fast-cma-es/blob/master/ODE.adoc[ODE] for results solving ODE in the objective function and
check https://github.com/dietmarwo/fast-cma-es/tree/master/examples[examples] for mechanical component design problems.  

=== Space Mission Design

==== Coordinated parallel retry 

Coordinated parallel retry is a super-linear scaling meta algorithm optimized for modern high core count CPUs. 
The following tests were performed on an AMD 3950x 16 core processor executing 32 retries in parallel.
As test problems we use ESAs GTOP problem database:

- https://www.esa.int/gsp/ACT/projects/gtop/cassini1/[Cassini1], https://www.esa.int/gsp/ACT/projects/gtop/cassini2/[Cassini2], https://www.esa.int/gsp/ACT/projects/gtop/rosetta/[Rosetta], https://www.esa.int/gsp/ACT/projects/gtop/gtoc1/[GTOC1], https://www.esa.int/gsp/ACT/projects/gtop/messenger_reduced/[Messenger reduced], https://www.esa.int/gsp/ACT/projects/gtop/messenger_full/[Messenger full] and https://www.esa.int/gsp/ACT/projects/gtop/tandem/[Tandem 6 constrained]

https://doi.org/10.1016/j.asoc.2020.106451[G-CLDE paper] and http://www.midaco-solver.com/data/pub/PDPTA20_Messenger.pdf[MXHCP paper] show
actual results of state of the art algorithms for the GTOP benchmarks. Usually mean / sdev and best results are shown for a number of
runs executed for each algorithm. This is because these algorithms cannot reliably solve these problems in a reasonable time. Here we show
the progress of the best value found over time for 20 runs of the coordinated parallel retry. Beside Messenger Full which needs more evaluations (see https://github.com/dietmarwo/fast-cma-es/blob/master/README.adoc[README]) the coordinated retry finds the best known solution in all runs. 

Initially the coordinated retry was developed as a meta algorithm for CMA-ES. It removes most weaknesses of CMA-ES. But sequences of differential evolution followed by CMA-ES, although slightly slower wrt. execution time, produce better results for very hard to solve problems.  Now we compare CMA-ES, DE->CMA-ES and GCL-DE->CMA-ES as base algorithm of the coordinated retry. Both differential evolution variants are configured to work optimal in this context and produce similar results, but GCL-DE is superior when used stand-alone.

To reproduce the results or check another CPU use https://github.com/dietmarwo/fast-cma-es/blob/master/examples/advexamples.py[advexamples.py].

==== Coordinated parallel retry of CMA-ES

image::Cassini1_cma_cpp_coordinated_parallel_retry.png[]

image::Cassini2_cma_cpp_coordinated_parallel_retry.png[]

image::Rosetta_cma_cpp_coordinated_parallel_retry.png[]

image::GTOC1_cma_cpp_coordinated_parallel_retry.png[]

image::messenger_reduced_cma_cpp_coordinated_parallel_retry.png[]

image::messenger_full_cma_cpp_coordinated_parallel_retry.png[]

image::Tandem_6_cma_cpp_coordinated_parallel_retry.png[]

==== Coordinated parallel retry of DE->CMA-ES

image::Cassini1_de_cpp_cma_cpp_coordinated_parallel_retry.png[]

image::Cassini2_de_cpp_cma_cpp_coordinated_parallel_retry.png[]

image::Rosetta_de_cpp_cma_cpp_coordinated_parallel_retry.png[]

image::GTOC1_de_cpp_cma_cpp_coordinated_parallel_retry.png[]

image::messenger_reduced_de_cpp_cma_cpp_coordinated_parallel_retry.png[]

image::messenger_full_de_cpp_cma_cpp_coordinated_parallel_retry.png[]

image::Tandem_6_de_cpp_cma_cpp_coordinated_parallel_retry.png[]

==== Coordinated parallel retry of GCL-DE->CMA-ES

image::Cassini1_gclde_cpp_cma_cpp_coordinated_parallel_retry.png[]

image::Cassini2_gclde_cpp_cma_cpp_coordinated_parallel_retry.png[]

image::Rosetta_gclde_cpp_cma_cpp_coordinated_parallel_retry.png[]

image::GTOC1_gclde_cpp_cma_cpp_coordinated_parallel_retry.png[]

image::messenger_reduced_gclde_cpp_cma_cpp_coordinated_parallel_retry.png[]

image::messenger_full_gclde_cpp_cma_cpp_coordinated_parallel_retry.png[]

image::Tandem_6_gclde_cpp_cma_cpp_coordinated_parallel_retry.png[]

==== Comparison with nature-inspired metaheuristic optimizers

https://github.com/7ossam81/EvoloPy[EvoloPy] implements a list of nature-inspired metaheuristic 
https://github.com/7ossam81/EvoloPy/tree/master/optimizers[optimizers] partly described
https://github.com/7ossam81/EvoloPy/wiki/List-of-optimizers[here]. 

All of these algorithms support boxed boundaries and are implemented single threaded. We will use them to check what can be gained
from parallelization using fcmaes coordinated retry. "DCD" is the old default algorithm DE->CMA starting with 1500 evaluations
per optimization run. "DCX" is DE->CMA starting with 1000*X evaluations. Every 100 optimizations this number is incremented. 
As test problems we use again ESAs GTOP problem database and the AMD 3950x 16 core processor. For the nature inspired algorithms 20000 iterations were performed. The fcmaes algorithms were limited by the number of retries, `4800`/X for DCX. For all tests 3 repetitions were performed and the mean result was plotted. 

* https://www.esa.int/gsp/ACT/projects/gtop/cassini1/[Cassini1]

image::st-conv-Ca1.png[]
image::mt-conv-Ca1.png[]

* https://www.esa.int/gsp/ACT/projects/gtop/cassini2/[Cassini2]

image::st-conv-Ca2.png[]
image::mt-conv-Ca2.png[]

* https://www.esa.int/gsp/ACT/projects/gtop/rosetta/[Rosetta]

image::st-conv-Ros.png[]
image::mt-conv-Ros.png[]

* https://www.esa.int/gsp/ACT/projects/gtop/tandem/[Tandem 6 constrained]

image::st-conv-Tan.png[]
image::mt-conv-Tan.png[]

* https://www.esa.int/gsp/ACT/projects/gtop/gtoc1/[GTOC1]

image::st-conv-Gt1.png[]
image::mt-conv-Gt1.png[]

* https://www.esa.int/gsp/ACT/projects/gtop/messenger_reduced/[Messenger reduced]

image::st-conv-Mes.png[]
image::mt-conv-Mes.png[]

* https://www.esa.int/gsp/ACT/projects/gtop/messenger_full/[Messenger full]

image::st-conv-Mef.png[]
image::mt-conv-Mef.png[]

==== Comparison of fcmaes and scipy optimization algorithms

Next we check the difference of the coordinated retry with a simple retry applied to several
fcmaes and scipy optimization algorithms using again the AMD 3950x 16 core processor.

The following optimization algorithms were tested:

- sequence DE -> CMA, the old default algorithm (now it is (DE | GLC-DE) -> CMA)
- CMA - {cpp} implementation
- DE - differential evolution, {cpp} implementation
- sequence DA -> CMA
- DA - dual annealing, {cpp} implementation
- scipy dual annealing
- scipy differential evolution 

The coordinated retry mechanism achieves good results with the scipy python optimization
algorithms differential evolution and dual annealing. 
But the sequence DE -> CMA achieves the most consistent results, beside messenger full all
problems can be solved in under one minute, messenger full needs about 1.5 hours. 
 
If you want to reproduce the results shown here, check 
https://github.com/dietmarwo/fast-cma-es/blob/master/examples/examples.py[examples.py] and 
https://github.com/dietmarwo/fast-cma-es/blob/master/examples/advexamples.py[advexamples.py].

image::Cassini1_de_cpp_cma_cpp.png[]
image::Cassini1_cma_cpp.png[]
image::Cassini1_de_cpp.png[]
image::Cassini1_da_cpp_cma_cpp.png[]
image::Cassini1_da_cpp.png[]
image::Cassini1_scipy_da.png[]
image::Cassini1_scipy_de.png[]

image::Cassini2_de_cpp_cma_cpp.png[]
image::Cassini2_cma_cpp.png[]
image::Cassini2_de_cpp.png[]
image::Cassini2_da_cpp_cma_cpp.png[]
image::Cassini2_da_cpp.png[]
image::Cassini2_scipy_da.png[]
image::Cassini2_scipy_de.png[]

image::GTOC1_de_cpp_cma_cpp.png[]
image::GTOC1_cma_cpp.png[]
image::GTOC1_de_cpp.png[]
image::GTOC1_da_cpp_cma_cpp.png[]
image::GTOC1_da_cpp.png[]
image::GTOC1_scipy_da.png[]
image::GTOC1_scipy_de.png[]

image::Rosetta_de_cpp_cma_cpp.png[]
image::Rosetta_cma_cpp.png[]
image::Rosetta_de_cpp.png[]
image::Rosetta_da_cpp_cma_cpp.png[]
image::Rosetta_da_cpp.png[]
image::Rosetta_scipy_da.png[]
image::Rosetta_scipy_de.png[]

image::Tandem_de_cpp_cma_cpp.png[]
image::Tandem_cma_cpp.png[]
image::Tandem_de_cpp.png[]
image::Tandem_da_cpp_cma_cpp.png[]
image::Tandem_da_cpp.png[]
image::Tandem_scipy_da.png[]
image::Tandem_scipy_de.png[]

image::messenger_reduced_de_cpp_cma_cpp.png[]
image::messenger_reduced_cma_cpp.png[]
image::messenger_reduced_de_cpp.png[]
image::messenger_reduced_da_cpp_cma_cpp.png[]
image::messenger_reduced_da_cpp.png[]
image::messenger_reduced_scipy_da.png[]
image::messenger_reduced_scipy_de.png[]

image::messenger_full_de_cpp_cma_cpp.png[]
image::messenger_full_cma_cpp.png[]
image::messenger_full_de_cpp.png[]
image::messenger_full_da_cpp_cma_cpp.png[]
image::messenger_full_da_cpp.png[]
image::messenger_full_scipy_da.png[]
image::messenger_full_scipy_de.png[]

These experiments can be reproduced by executing

[source,python]
----
import fcmaes.examples
import fcmaes.advexamples
examples.test_all()
advexamples.test_all()
----

Check optimizer.log for the results.
   
=== Protein Folding

The AB off-lattice models of protein folding is another interesting real life optimization benchmark. 
There are two different popular 3D models, see
https://www.researchgate.net/publication/7839084_Multicanonical_Study_of_Coarse-Grained_Off-Lattice_Models_for_Folding_Heteropolymers[Coarse-Grained_Off-Lattice_Models] for a comparison. 

The generalization of the 2D AB off-lattice model to 3D is called "AB model I" in the paper, 
"AB model II" makes the coupling between successive bonds “antibending” which leads to results
more similar to what we find in nature. Both models can be used to benchmark optimization algorithms. 

Optimization aims at finding a folding of the protein which has the
lowest energy level as determined by the formula given for the model. This energy can be derived
by the position of the two types of molecules (denoted 'A' and 'B'). Distance of two consecutive
molecules is always 1, so the input vector consists of two angles for each successive bond vector - 
actually we need only one angle for the first one. So the dimension of the problem is 2n-3 where
n is the length of the AB sequence. Most approaches at optimizing protein folding adapt the optimization
process to the structure of the problem itself. But there is a generic idea, 
https://www.researchgate.net/publication/309179699_Differential_evolution_for_protein_folding_optimization_based_on_a_three-dimensional_AB_off-lattice_model[temporal locality] for differential evolution developed in this context 
which is integrated in fcmaes because it has been shown useful in the context of coordinated retry and in an
optimization sequence with CMA-ES. 

Generic optimization cannot solve AB_off-lattice_model tasks for higher dimensions, but if you have
no alternative you could try a DA->CMA sequence with very high evaluation limit - 10⁷- with 80% of the budget 
assigned to DA in connection with the normal parallel retry. Takes ages to complete, but for
the 2EWH sequence of length 98 we found an solution with AB model I energy of -228 - compared to -245 from https://www.sciencedirect.com/science/article/pii/S0020025518303335[Protein folding optimization] using an algorithm optimized for protein folding. 

image::ABbig.png[]

The comparison we show here is for the much shorter sequence "BAAAAAABAAAABAABAABB" called "20.1" in 
https://www.researchgate.net/publication/7839084_Multicanonical_Study_of_Coarse-Grained_Off-Lattice_Models_for_Folding_Heteropolymers[Coarse-Grained_Off-Lattice_Models] and we use the "AB model II" which 
results in higher energy numbers. 

image::ABsmall.png[]

As for the space trajectory design benchmarks we limit the maximal number of evaluations to 50000 per run. 
The reference result from the paper is −58.306, it is not reached by any optimization algorithm tested. 
For "messenger_full" coordinated retry finally worked when we increased the effort spent on each run to 2 hours,
for the AB_off-lattice_model this doesn't work. We advise against using the coordinated
retry for this problem, use the simple retry instead. Increase the maximum evaluation limit and use Dual Annealing - 
or a DA-CMA sequence. Or adapt the optimization algorithms to the problem. Coordinated retry helps with CMA and DE, 
but the results are inferior to what you get using Dual Annealing. 

We see that Dual Annealing can approach -58 in under one hour if you use the c++ version, the scipy version is about factor 4 slower. The mediocre results for the DA-CMA sequence indicate that the default budged distribution (20/80) should
be reversed to (80/20) for this problem. It also helps to decrease the popsize for CMA to 13. 

image::ab_cluster_3d2_de_cpp_cma_cpp.png[]
image::ab_cluster_3d2_cma_cpp.png[]
image::ab_cluster_3d2_de_cpp.png[]
image::ab_cluster_3d2_da_cpp_cma_cpp.png[]
image::ab_cluster_3d2_da_cpp.png[]
image::ab_cluster_3d2_scipy_da.png[]
image::ab_cluster_3d2_scipy_de.png[]

=== Circle in Square

Suppose, you have to cut circles with a fixed diameter from a square-shaped material.
How can you minimize the waste? A variation of this problem is that
you want to maximize the diameter for a given number of circles.  
You can find optimal solutions for any N < 10000 here 
http://hydra.nat.uni-magdeburg.de/packing/csq/csq.html[CSQ]

There exists an interesting problem specific algorithm 
https://books.google.de/books?id=dY9CAAAAQBAJ&printsec=frontcover[Pulsating Disk Shaking]
far superior to what a generic optimizer can achieve. Here is a nearly optimal 
solution computed with PDS for N = 287:

image::287.png[]

So you should not use a generic optimization algorithm for this kind of packing problem for
larger number of objects, but it is still interesting to investigate "how far off" we are here.
And for a small number of objects (< 50), you get decent results, so applying fcmaes
can be an option.   

The results are for the "place 100 circles in a square problem" which has an optimal 
solution allowing for a distance of
http://hydra.nat.uni-magdeburg.de/packing/csq/csq.html#Overview[0.1145]. None of the
algorithms tested beats 0.10 - we could pack 128 circles with this distance in a square, 
so we are wasting 28 circles. It is still interesting to compare the results which show an
advantage for CMA based approaches. Again there is nothing to gain by applying the 
coordinated retry - at least not for the best optimizers. 

image::CircInSquare_de_cpp_cma_cpp.png[]
image::CircInSquare_cma_cpp.png[]
image::CircInSquare_de_cpp.png[]
image::CircInSquare_da_cpp_cma_cpp.png[]
image::CircInSquare_da_cpp.png[]
image::CircInSquare_scipy_da.png[]
image::CircInSquare_scipy_de.png[]

